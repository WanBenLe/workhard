

平行趋势对函数形式不敏感<->CDF满足平行趋势类型条件
1.处理是似随机分配的
2.每个处理组分布在时间上是稳定的
3.前两种情况的混合:总体是由以下两种子总体混合的
a.似随机的对照与控制子总体
b.时间上稳定的非处理潜在结果分布子总体



When Is Parallel Trends Sensitive to Functional Form? Jonathan Rothy, ECTA, 2023

定义:平行趋势假设对函数形式不敏感,有

$E[g(Y_{i1}(0)|D_{i}=1)]-E[g(Y_{i0}(0)|D_{i}=1)] \\=E[g(Y_{i1}(0)|D_{i}=0)]-E[g(Y_{i0}(0)|D_{i}=0)]$

1.可证得等价于CDF满足相关条件,且对于连续数据等价于PDF满足同样条件

2.若对于所有的$y \in R,d,t \in {0,1}$,$Y_{it}(0)|D_{i}=d$有个关联(?)于一个共同(?)支配(?)正$\sigma$有限测度(RN导数),有当且仅当条件的条件如下

存在$\theta \in [0,1]$和决定于与组和时间CDF $G_{t}(.)$和$H_{d}(.)$,对于所有的$y \in R,d,t \in [0,1]$有

$F_{Y_{it}(0)|D_{i}=d}(y)=\theta G_{t}(y)+(1-\theta)H_{d}(y)$

于是有:

$F_{Y_{i,1}(0)|D_{i=1}}(y)=F_{Y_{i,0}(0)|D_{i=1}}(y)+F_{Y_{i,1}(0)|D_{i=0}}(y)-F_{Y_{i,0}(0)|D_{i=0}}(y)$

左边是个递增的CDF,右边可以上假设检验,CDF会让右边$y \rightarrow \infty,0\rightarrow1$

$f_{Y_{i,1}(0)|D_{i=1}}(y)=f_{Y_{i,0}(0)|D_{i=1}}(y)+f_{Y_{i,1}(0)|D_{i=0}}(y)-f_{Y_{i,0}(0)|D_{i=0}}(y) \geq 0, \forall y \in \mathcal{Y}\\ PMF:f_{Y_{i,t}(0)|D_{i=d}}(y)=E[1[Y_{it}=y|D_{i}=d]]$

进一步的,可以用上面右边的样本估计下面的隐含PMF,并

1.使用矩不等式进行测试(Ivan A. Canay, 2017)

2.可视化隐含PMF观察可能的分布平行趋势假设的违反

3.对于连续的Y还有连续的矩不等式测试或离散化处理





Practical and Theoretical Advances in Inference for Partially Identified Models, Ivan A. Canay, Advances in Economics and Econometrics, 2017 

在部分识别的情况下,置信域比点的概念更常用一些,对于部分识别存在一些矩不等式的假设检验

$\lim_{n\to \infty}\inf_{P \in \mathbb{P}}\inf_{\theta \in \Theta_{0}(P)} P\{\theta \in C_{n}\} \geq 1-\alpha$

如果$\theta$关于$\mathbb{P}$是被识别的,有

$\lim_{n\to \infty}\inf_{P \in \mathbb{P}} P\{\theta \in C_{n}\} \geq 1-\alpha$

前者可以快乐对偶出一些独立的假设检验$H_{\theta}:\theta \in \Theta_{0}(P)$即

$\lim_{n\to \infty}\sup_{P \in \mathbb{P}}\sup_{\theta \in \Theta_{0}(P)} E_{P}[\phi_{n}(\theta) ] \leq \alpha$

于是开始推断矩不等式

$\Theta_{0}(P)=\{\theta \in \Theta:E_{P}[m(W_{i},\theta)]\le 0\}$

上面对偶出来的假设检验变成了这玩意

$H_{\theta}:E_{P}[m(W_{i},\theta)]\le 0$

下面是一些记号

$\mu(\theta,P)=E_{P}[m(W_{i},\theta)]$

$\Omega(\theta,P)=Corr_{P}[m(W_{i},\theta)]$

$D(\theta,P)=diag(\sigma_{j}(\theta,P):1\le j \le k)$

$\sigma_{j}^{2}(\theta,P)=Var_{P}[m_{j}(W_{i},\theta)]$

对于经验分布$\hat{P_{n}}$有

$\bar{m_{n}}(\theta)=\mu(\theta,\hat{P_{n}})$

$\hat{\Omega}_{n}(\theta)=\Omega(\theta,\hat{P_{n}})$

$\hat{D}_{n}(\theta)=D(\theta,\hat{P_{n}})$

有以下统计检验量,有三种估计方法

$T_{n}(\theta) \equiv T(\hat{D}^{-1}_{n}(\theta)\sqrt{n}\bar{m_{n}}(\theta),\hat{\Omega}_{n}(\theta))$

a.调整矩估计

$T^{mmm}_{n}(\theta)=\sum_{1\le j \le k}\max\{\frac{\sqrt{n}\bar{m_{n,j}(\theta)}}{\hat{\sigma}_{n,j}(\theta)},0\}^{2}$

b.最大化

$T^{max}_{n}(\theta)=\max\{\max_{1\le j \le k}\frac{\sqrt{n}\bar{m_{n,j}(\theta)}}{\hat{\sigma}_{n,j}(\theta)},0\}$

c.调整伪似然比

$T^{ad,qlr}_{n}(\theta)=\inf_{t \in R^{k}:t\le0}(\hat{D}^{-1}_{n}(\theta)\sqrt{n}\bar{m_{n}}(\theta)-t)'\widetilde{\Omega}_{n}(\theta)^{-1}(\hat{D}^{-1}_{n}(\theta)\sqrt{n}\bar{m_{n}}(\theta)-t)$

$\hat{\sigma}_{n,j}(\theta)\equiv\sigma_{j}(\theta,\hat{P_{n}})$

$\widetilde{\Omega}_{n}(\theta)=\max\{\epsilon-\det(\hat{\Omega}_{n}(\theta)),0\}I_{k}+\hat{\Omega}_{n}(\theta)$

$\widetilde{\Omega}_{n}(\theta)$的调整处理了近奇异矩阵的情况

为了比较$T_{n}(\theta)$的估计,引入下面公式

$J_{n}(x,s(\theta),\theta,P)=P\{T(\hat{D}^{-1}_{n}(\theta)\sqrt{n}(\bar{m_{n}}(\theta)-\mu(\theta,P)))+\hat{D}^{-1}_{n}(\theta)s(\theta),\hat{\Omega}_{n}(\theta)\le x\}$

前者可以通过

1.用$J_{n}(x,s(\theta),\theta,\hat{P_{n}})$上非参bootstrap估计

2.用满足$m(W_{i},\theta)\backsim N(\bar{m}_{n}(\theta),\hat{\Sigma_{n}(\theta)})$的$\widetilde{P_{n}}$估计$J_{n}(x,s(\theta),\theta,\widetilde{P_{n}})$

对于固定的$\theta \in \Theta_{0}(P),P \in \mathbb{P},\Sigma(\theta,P)=Var_{P}[m(W_{i},\theta)]$,有

$|\sqrt{n}(\bar{m_{n}}(\theta)-\mu(\theta,P)))|\xrightarrow{d}|N(0,\Sigma(\theta,P))|$

于是$J_{n}(x,s(\theta),\theta,P)$左边的部分为0

为了倒腾上面的提到的$H_{\theta}:E_{P}[m(W_{i},\theta)]\le 0$

当然要满足这个条件$\lim_{n\to \infty}\sup_{P \in \mathbb{P}}\sup_{\theta \in \Theta_{0}(P)} E_{P}[\phi_{n}(\theta) ] \leq \alpha$

下面提供了5个方法估计矩不等式,若下述的一致可积的充分条件,前者的条件也是满足的:

$\exist \sigma>0, \sup_{P \in \mathbb{P}}\sup_{\theta \in \Theta_{0}(P)}E_{P}[(\frac{m_{j}(W_{i},\theta)-\mu(\theta,P)}{\sigma_{j}(\theta,P)})^{2+\delta}]<\infty$

1.最不利测试

$\phi^{lf}_{n}(\theta)\equiv I\{T_{n}(\theta)>\hat{J}^{-1}_{n}(1-\alpha,0_{k},\theta)\}$

右边的部分估计上面提过了,最保守,本质上就是$\mu(\theta,P)=0$

当然最不利测试对于$\sup_{\mu \in \Pi{0}}E_{\mu}[\phi]\le \alpha$是$\alpha$-可容许($\forall \mu \in \Pi_{1}, E_{\mu}[\widetilde{\phi}]\ge E_{\mu}[\phi]$):和$d$-可容许(加上$\forall \mu \in \Pi_{0}, E_{\mu}[\widetilde{\phi}]\le E_{\mu}[\phi]$)的.其中,

$\alpha$-可容许意味着$\forall \mu \in \Pi_{1}, E_{\mu}[\widetilde{\phi}]= E_{\mu}[\phi]$

$d$-可容许意味着$\forall \mu \in \Pi, E_{\mu}[\widetilde{\phi}]= E_{\mu}[\phi]$

2.子抽样

$0<b=b_{n}<n,b\rightarrow \infty.b/n\rightarrow 0,N_{n}=(n,b_{n})$

在第$\mathscr{l}$次子抽样中估计$T_b(\theta)$记为$T_{b,\mathscr{l}(\theta)}$,有$J_{n}(x,\sqrt{n}\mu(\theta,P),\theta,P)$的子抽样估计

$L_{n}(x,\theta)=\frac{1}{N_{n}}\Sigma_{1\le \mathscr{l} \le N_{n}}I\{T_{b,\mathscr{l}(\theta)}\le x\}$

$\phi^{sub}_{n}(\theta)=I\{T_{n}(\theta)>L_{n}^{-1}(1-\alpha,\theta)\}$

子采样数量对估计很关键,参考以下文献

$Politis, D. N., J. P. Romano, and M. Wolf (1999): Subsampling, Springer, New York.$

3.广义矩选择

$\phi^{gms}_{n}(\theta) \equiv I\{T_{n}(\theta)>\hat{J}^{-1}_{n}(1-\alpha,\hat{s}^{gms}_{n}(\theta),\theta)\}$

估计同最不利测试上面写了

$\hat{s}^{gms}_{n}(\theta)=(\hat{s}^{gms}_{n,1}(\theta),...,\hat{s}^{gms}_{n,k}(\theta))'$

$\begin{equation}
\hat{s}^{gms}_{n,j}(\theta)=
\begin{cases}
0 & \text{ $ \frac{\sqrt{n}\bar{m_{n,j}(\theta)}}{\hat{\sigma}_{n,j}(\theta)}>-\kappa_{n} $ } \\
-\infty & \text{ $ others $ }
\end{cases}
\end{equation}$

$0<\kappa_{n}\rightarrow \infty,\kappa_{n}/\sqrt{n}\rightarrow0$例如$\kappa_{n}=\log n$

若$\lim_{n\rightarrow\infty}\frac{\kappa_{n}\sqrt{b_{n}}}{\sqrt{n}}=0$,广义矩选择在极限power上比子抽样更好

4.改进矩选择

实际上$0<\kappa_{n}\rightarrow \infty,\kappa_{n}/\sqrt{n}\rightarrow0$不现实

考虑$\hat{J}^{-1}_{n}(1-\alpha,\hat{s}^{rms}_{n}(\theta),\theta)$,估计同最不利测试上面写了

和$\hat{s}^{rms}_{n}(\theta)=(\hat{s}^{rms}_{n,1}(\theta),...,\hat{s}^{rms}_{n,k}(\theta))'$

$\begin{equation}
\hat{s}^{rms}_{n,j}(\theta)=
\begin{cases}
0 & \text{ $ \frac{\sqrt{n}\bar{m_{n,j}(\theta)}}{\hat{\sigma}_{n,j}(\theta)}>-\kappa,\kappa>0 $ } \\
-\infty & \text{ $ others $ }
\end{cases}
\end{equation}$

为了cover$\mu_{j}(\theta,P)=0$的部分,需要对检验进行调整

$\phi^{rms}_{n}(\theta) \equiv I\{T_{n}(\theta)>\hat{J}^{-1}_{n}(1-\alpha,\hat{s}^{rms}_{n}(\theta),\theta)+\hat{\eta}_{n}(\theta)\}$

$\hat{\eta}_{n}(\theta)\equiv\eta^{*}(\hat{\Omega}_{n}(\theta),\kappa)$可以通过求解以下优化问题得到

$\eta^{*}(\Omega^{*},\kappa)\equiv\inf\{\eta>0: \sup_{s^{*}\in \mathbb{R}^{k}:s^{*}\le 0}\\P\{T(Z+s^{*},\Omega^{*})>\hat{J}^{-1}(1-\alpha,\hat{s}^{rms,*}(Z+s^{*},\kappa),\Omega^{*})+\eta\}\le \alpha\}$

$s^{*}$是$\sqrt{n}\mu(\theta_{n},P_{n})$的极限$\Omega^{*}$是$\hat{\Omega}_{n}(\theta_{n})$的概率极限,$Z\backsim N(0,\Omega^{*})$

$\begin{equation}
\hat{s}_{j}^{rms,*}(Z+s^{*},\kappa)=
\begin{cases}
0 & \text{ $ Z_{j}+s^{*}_{j} >\kappa $ } \\
-\infty & \text{ $ others $ }
\end{cases}
\end{equation}$

$\hat{\kappa}_{n}(\theta)=k^{*}(\hat{\Omega)}_{n}(\theta)$可以通过最大化下面的等权平均power得到

$\frac{1}{|A|}\sum_{a \in A}P\{T(Z+a,\Omega^{*})>J^{-1}(1-\alpha,s^{rms,*}(Z+a,\kappa),\Omega^{*})+\eta^{*}({\Omega}^{*},\kappa)\}\}$

由于算起来有亿点点难,$Andrews, Barwick (2012)$用表格给出了$\kappa\le10,\alpha=5%$的$\kappa^{*},\eta^{*}(\Omega^{*},\kappa^{*}(\Omega^{*}))$

5.二阶段测试

power可能比上面的都要好

第一步

构造$M_{n}(\theta,1-\beta)$

$\lim_{n\to \infty}\inf_{P \in \mathbb{P}}\inf_{\theta \in \Theta_{0}(P)} P\{\sqrt{n}\mu(\theta,P)\in M_{n}(\theta,1-\beta)\} \geq 1-\beta$

定义$K_n(x,\theta,P)\equiv P \{ \max_{1\le j\le k}\frac{\sqrt{n}(\mu_{j}-\bar{m_{n}(\theta))}}{\hat{\sigma}_{n,j}(\theta)}\le x\}$

有$M_{n}(\theta,1-\beta) \equiv \{ \mu \in \mathbb{R}^{k} \max_{1\le j\le k}\frac{\sqrt{n}(\mu_{j}-\bar{m_{n}(\theta))}}{\hat{\sigma}_{n,j}(\theta)}\le \hat{K}_n^{-1}(1-\beta,\theta)\}$

$\hat{K}_n(1-\beta,\theta)$同样的可以用$K_n(x,\theta,\hat{P}_{n})$或者$K_n(x,\theta,\widetilde{P_{n}}(\theta))$估计

于是有第二步

$\phi^{ts}_{n}(\theta) \equiv I\{T_{n}(\theta)>\hat{J}^{-1}_{n}(1-\alpha+\beta,\hat{s}^{ts}_{n},\theta)\}$

$\hat{s}^{ts}_{n}(\theta)=(\hat{s}^{ts}_{n,1}(\theta),...,\hat{s}^{ts}_{n,k}(\theta))'$

$\hat{s}^{ts}_{n,j}(\theta)=\min\{\sqrt{n}\bar{m_{n}(\theta})+\hat{\sigma}_{n,j}(\theta)\hat{K}^{-1}_n(1-\beta,\theta),0\}$

$\beta=\alpha/10$可能够用了,不用撸改进矩筛选方法的复杂优化

如果$T_{n}(\theta)=0,\bar{m_{n}(\theta})\le0$,有些约束是多余的