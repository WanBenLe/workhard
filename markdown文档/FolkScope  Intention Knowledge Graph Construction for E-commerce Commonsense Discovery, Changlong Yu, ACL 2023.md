#### FolkScope : Intention Knowledge Graph Construction for E-commerce Commonsense Discovery, Changlong Yu, ACL 2023

提出了 FolkScope,用于揭示人类购买物品的思维结构意图知识图构建框架.

![image-20240403134207898](C:\Users\SFC\AppData\Roaming\Typora\typora-user-images\image-20240403134207898.png)

LLM 通过电子商务特定的提示生成意图(开放原因或者ConceptNet的18个类别之一的谓词)来解释购物行为,再将采样意图的合理性和典型性标签注释为训练数据,融入分类模型,最后为了结构化断言,提出模式挖掘以聚合相似断言,并概念化进一步聚合得到抽象知识

合理性:断言在其属性.用法.功能等方面有效的可能性有多大

典型性:断言反映导致用户行为的特定功能的程度,要求有1.信息性:购物环境的关键信息2.因果关系:捕捉用户行为的典型意图



##### 知识生成用户行为数据采样

使用服装鞋珠宝/电子产品比较容易因为"需要"共同购买的共同购买数据.

###### prompt生成的模版

对于HasA的prompt如下所示,[GEN]是用于生成的标记,item标题需要启发式规则处理,例如删除重复单词等

“A user bought ‘item 1’ and ‘item 2’ because they both have [GEN]” 

使用OPT 30b生成,最大生成长度=100,使用核采样(p = 0.9)生成3个断言,并句子不完整的数据和Spacy分句后提取最长断言的第一个句子.

![image-20240403135140722](C:\Users\SFC\AppData\Roaming\Typora\typora-user-images\image-20240403135140722.png)

###### 两步注释与填充

使用 Amazon Mechanical Turk(MTurk)注释,为注释者提供了一对共同购买的商品,其中包含每个商品的标题.类别.购物 URL 以及来自我们采样元数据的三个图像,并对断言搜集3个合理性注释并服从多数结果.

基于66K注释对训练分类模型DeBERTa-large

第二步典型性注释在合理的中选择,要求注释者判断:断言对于购买行为来说是信息丰富的,选项为:

强烈接受(+1)/弱接受(0.5)/拒绝(0)/难以置信(-1),取5个结果并算平均分,大于0.8为正例,小于0.2为负例的60K注释训练分类模型DeBERTa-large

最终保留合理性得分大于0.5的知识

##### 知识聚合

###### 模式挖掘对齐相似生成

每个关系采样90k ,同时获取词形还原的标记.词性标签和命名实体,要求模式完美匹配(该模式是最长的模式,并且没有其他候选模式可以匹配)超过500次,模式挖掘pipeline为:1. gSpan图模式挖掘算法(取频率>500) 2. igraph的VF2算法并使用最长优先贪婪策略来检查完美匹配频率3.人工评估和修订

最后得到256种模式,并据此构建知识图谱

头:共同购买产品对

关系:见上表

尾:256种模式之一

还有相应的合理性和典型性分数.



######  概念化

概念化过程将一个提取的断言 e 映射到具有概念 c 的多个概念化断言上.概念化权重$P(c|e)$​可以通过 Probase 中 IsA(e,c) 的likelihood来确定,用的是ASER 2.0.



##### 推荐系统

由于前者的个体化因素,人类情境关系的断言比物品属性的关系合理性分数更低和更长的长度.预测的典型性得分不如合理性得分准确,这是由于概念化的噪声引入和抽象知识本就不那么典型.

TransE改成

$L=\gamma+d(\frac{p_1+p_2}{2}+r,e)-d(\frac{p'_1+p'_2}{2}+r,e)$,$\gamma$是边际参数,4个p是emb,r是关系emb,e是尾部emb,d是欧几里德距离

学习出来的emb可以作为新的额外特征用于推荐