#### Dataset Quantization, Daquan Zhou, ICCV 2023

合成新数据存在1.由于泛化能力差不兼容未知网络结构2.大数据集压缩率低的扩展性低3.合成集二次方的计算成本

核心集方法由于较低的数据保留率会使得样本失去多样性进而有偏.

提出数据集量化(DQ),提出将大规模数据集压缩成高压缩率.可用于未知网络架构训练的小数据集的新框架,性能几乎无损.

##### 核心集GraphCut分析

$D=\{(x_k,y_k)\}^M_{k=1}$,有M个样本并打算选k个样本,核心集$S_1^1=\empty,S_1^{k}=S_1^{k-1}\cup x_k$,在特征提取器$f(\cdot)$最大化以下的子模增益$P(x_k)$:

$P(x_k)=\sum_{p\in S_1^{k-1} }||f(p)-f(x_k)||^2_2-\sum_{p\in D /\ S_1^{k-1} }||f(p)-f(x_k)||^2_2$​

但由于$K<<M$导致公式第一部分远小于第二部分,后者仅要求与剩余集合的距离而没有保证样本多样性.可证明$x_k$选择需要满足

$||f(x_k)||^2_2\le(2k/(M-2k))^2(R_1^{k-1})^2$,$R_1^{k-1}=max_{p\in S_1^{k-1}}||f(p)||_2$​

$M>>K$时,$f(x_k)$会在$(R_1^{k-1})^2$​内或离群点.

为了解决这个问题,可以在选择$S_{n+1}$的时候使用$D_{n-1} /\ S_{n},D_0=D$,由于选择了最紧凑子集,$R_2^{k-1}$会变大,并且M会从$(M-2k)$减少至$(M-K-2k)$,进而缓解了核心集选择导致的样本有偏多样性不足的问题.

##### 数据量化DQ

###### 数据箱生成算法

输入:原始数据集D,箱数量N,箱容量K,score函数$P(\cdot)$

for n in range(N-1):

​	$S_1^n=\empty,S_0^n=\empty$

​	for k in range(K):

​		for $x_i$ in $D/\ S_n^k$:

​			$P(x_i)=\sum_{p\in S_1^{i-1} }||f(p)-f(x_i)||^2_2-\sum_{p\in D /\ S_1^{i-1} }||f(p)-f(i_k)||^2_2$​

​			$x^*\leftarrow arg \space max_{x\in D/\ S_n^k}P(x_i)$

​			$S_n^k\leftarrow S_n^{k-1}\cup x^*$

输出:N个箱$\{S_1,S_2,...,S_N\}$

1. 基于数据箱生成算法数据集分成不重叠箱体以最大化多样性增益
2. 每个箱使用抽样器$g(\cdot,\cdot)$对每个箱抽样得到$S^*=g(S_1,\rho)\cup g(S_2,\rho)\cup ,...,g(S_N,\rho)$,$\rho$是数据保留率,默认使用均匀抽样

3. 对于图像,进行分块,分块后丢弃无信息块和基于丢弃率$\theta$丢弃块并使用MAE(掩码自动编码器)重建.